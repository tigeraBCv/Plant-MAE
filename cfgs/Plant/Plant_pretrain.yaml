optimizer: {
  type: AdamW,
  kwargs: {
  lr: 0.001,
  weight_decay: 0.05}}

scheduler: {
  type: CosLR,
  kwargs: {
    epochs: 400,
    initial_epochs: 10}}

dataset: {
  train: { _base_: cfgs/dataset/Plant_part.yaml,
            others: {subset: 'train', npoints: 5000}},
  val: { _base_: cfgs/dataset/Plant_part.yaml,
            others: {subset: 'test', npoints: 5000}},
  test: { _base_: cfgs/dataset/Plant_part.yaml,
            others: {subset: 'test', npoints: 5000}},
  svm: {
          train: { _base_: cfgs/dataset/Plant_class_SVM.yaml,
                    others: {subset: 'train', num_points: 2048}},
          val: { _base_: cfgs/dataset/Plant_class_SVM.yaml,
                    others: {subset: 'test', num_points: 2048}},
          test: { _base_: cfgs/dataset/Plant_class_SVM.yaml,
                    others: {subset: 'test', num_points: 2048}}}
          }

model: {
  NAME: Point_M2AE_ST, #zhijia kp
  mask_ratio: 0.8,
  # tokenizers
  group_sizes: [32, 16, 8], #[64, 32, 32],#[8,16,64]#[16,32,64]
  num_groups: [512, 256, 64],
  # hierarchical encoder
  encoder_depths: [5, 5, 5],
  encoder_dims: [96, 192, 384],
  local_radius: [0.32, 0.64, 1.28],  # disabled for pre-training
  # hierarchical decoder
  decoder_depths: [1, 1],
  decoder_dims: [384, 192],
  decoder_up_blocks: [1, 1],
  concat_xyz: True,
  local_number: [8,16,16],
  # others
  drop_path_rate: 0.1,
  num_heads: 6,}

npoints: 5000
total_bs: 200
step_per_update: 1
max_epoch: 500
